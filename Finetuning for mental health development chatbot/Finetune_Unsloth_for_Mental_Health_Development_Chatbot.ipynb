{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/drive/1fgL7Ab7n3HC6roZWqrdvkX64nN6Lcm2Q?usp=sharing\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "id": "r8cZ4cah-9XT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " we performed continued fine-tuning of the TinyLlama 1.1B Chat model to create a specialized Mental Health Development Chatbot.\n",
    "A synthetic dataset consisting of 500 carefully designed mental health support dialogues was generated, covering a range of topics including managing anxiety, stress, loneliness, self-esteem, emotional resilience, and mindfulness practices.\n",
    "We formatted the dataset using the ChatML instruction-response style and fine-tuned the model for 100 steps using Unsloth\u2019s optimized SFTTrainer.\n",
    "After training, the fine-tuned TinyLlama chatbot was tested on new unseen prompts, successfully providing empathetic and relevant mental health advice.\n",
    "The final chatbot demonstrated an ability to generate supportive, informative, and context-appropriate responses, showing that even a lightweight model like TinyLlama can be effectively adapted to specialized domains with efficient continued fine-tuning."
   ],
   "metadata": {
    "id": "7PJ06TpgAwa7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGxtF7Pv9vt-",
    "outputId": "854a2aec-6d51-4c00-fd37-f511b3406ae4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#1 Install libraries\n",
    "!pip install -q unsloth \"torch>=2.1\" transformers peft datasets trl accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Import modules\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, pipeline\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "\n"
   ],
   "metadata": {
    "id": "SGf3DdvI97Yv"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3: Load TinyLlama-1.1B-Chat model\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=True,\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "1d9209d13b654afc98f935782224b412",
      "e6b00abb91d6454eb41b32a80da9c2fb",
      "c538270cc0b941ae9d7d451c4256bed6",
      "04ed42fd570348e1b6ebfe98a768506b",
      "90b9d2ea95b743a6b055248aa804def3",
      "d0d607d800ed424ab621875a88b5ada1",
      "ff057c430c7a46329746991b348db540",
      "852fd5bcdae041f298055b1e813c4587",
      "bca520ea923a42eab88a75b2db50fc09",
      "a7318ac5bf5844cf9ac05c0c1da8b671",
      "6373c80101eb444ebb6efed71da8af27",
      "7ee36cf31e2544eeaf95b4b9fcac6d8f",
      "af59a4d5d900475d961b42e491ad086e",
      "78b7ae921e764a8d9e42fa891dc9c138",
      "a0da1cc754fe4581a596198dec666dff",
      "624894cd3760406a89951b8ce968ff63",
      "ad965ff5210545718505c160178c3ba4",
      "920dac520578466e9cf9604cea821065",
      "16350778b87c45b5bacfe4c8f706a368",
      "74576c2e43964ed586091141bb8d5da0",
      "5dfcfde513c844d3964f4db3b735ec88",
      "2252b82d02f94beda8384fa4df5f3c96",
      "9e943db6d24c497ebc1078baa7ea0b9d",
      "a7adc0f2736c42a3b584375e8285090b",
      "2ee72353d6804d35997da0d053d1f64f",
      "470365c8d8bb40eca7c5e8a1e673385e",
      "10c664cda2b14c22b667f8b4e205e46a",
      "3f0ce98851c14c06b730007a1dda157d",
      "7293ddb22c6f433da6f0d1b68c1a3806",
      "ff17679ce77041cabf87a36088ca7cd4",
      "a1197e8edcee479f9c52d6ce02521dc0",
      "df0cdac23da4462ab5ecbc05d400c673",
      "6944a9dea66948f6987647056cffc69b",
      "ad3c95ea4ac14cbaa591a93cea6bf741",
      "aba37af283ee414c81a3fc21680cad34",
      "71a0a463fa7745a799b900fb3aedf5ff",
      "64030af9fc874de18d462a091187f67c",
      "b550da00084c411cad08e8c3346b924e",
      "59c9362621bf44d8b0878bbe97729cd3",
      "e29458e134574b338f09a2d34ca39fb8",
      "526fce41092d4b18b29758d196e0bd7f",
      "c40ef00236764b1d89bfa035d212624d",
      "7290fc57a95947ddb15d87c4bb7ac82b",
      "24693319abee406b954c680351096c99",
      "5884f9fc41f7425b83ab6b97f6acf749",
      "ff27ed42a9df45229b370c7d3a669e51",
      "693135e8280448e78cf1f00b5ebef0ac",
      "d7fb2c8329934b27bf5e4057a1eed9a2",
      "a0c2bce9e02b45cbb50d26dc622c8cbd",
      "c81f2a13ba484a7bb200d1b9ee5b08d6",
      "c9c124b091de45118d37e5ebc32b5310",
      "c32233f8f9cc438a8f1a8bbca92912f1",
      "ab894d99a24541e5b4585efcf88eb949",
      "58429749497643e7ad783fce9c040ce4",
      "91762d044db74a50838d686df9cc57a1",
      "c56bbb7da4904d4e8185fb06b0f9f831",
      "bf15e94bbcbe4e1d84ed109d6b0d0dc9",
      "12e3b58f6d2b40d09c9e7a1b70485ec3",
      "32a1706c47754a878ede781804d6cfbe",
      "4b517018f9bc4c00b1ce712c3d09b548",
      "cfd85ff118d44e39aaf81100104dba2e",
      "6d68ffb7ebb247b6bc4e0fef5720d147",
      "cb1196cb8bdd424ab0c5fe01e5fea8e5",
      "ff90cf4100d740c2a62cbe5a24438328",
      "b9d2a3bffba64b2ebdeaa65caeb5a6f3",
      "3cf4cebf54f049f7b726112eae931987"
     ]
    },
    "id": "TlX7TG9y97bZ",
    "outputId": "d498a065-3755-4e5f-a016-ef884ef844b4"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/762M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d9209d13b654afc98f935782224b412"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ee36cf31e2544eeaf95b4b9fcac6d8f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e943db6d24c497ebc1078baa7ea0b9d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad3c95ea4ac14cbaa591a93cea6bf741"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5884f9fc41f7425b83ab6b97f6acf749"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c56bbb7da4904d4e8185fb06b0f9f831"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.4.1 patched 22 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Generate 500 new mental health samples\n",
    "\n",
    "questions = [\n",
    "    \"How can I deal with anxiety before public speaking?\",\n",
    "    \"What should I do if I feel isolated from my friends?\",\n",
    "    \"How to handle panic attacks in crowded places?\",\n",
    "    \"What are healthy ways to manage work stress?\",\n",
    "    \"How can mindfulness improve my mental health?\",\n",
    "    \"What should I do when I feel emotionally exhausted?\",\n",
    "    \"How to support a colleague showing signs of burnout?\",\n",
    "    \"How does physical exercise impact mental wellbeing?\",\n",
    "    \"Tips for building a positive daily routine?\",\n",
    "    \"How can I gently encourage someone to seek therapy?\"\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    \"Practice breathing techniques, visualize success, and take things one step at a time.\",\n",
    "    \"Reach out to trusted people, join group activities, or volunteer for causes you enjoy.\",\n",
    "    \"Focus on grounding yourself using techniques like naming five things you see or feel.\",\n",
    "    \"Prioritize tasks, delegate when possible, and take regular short breaks.\",\n",
    "    \"Mindfulness improves focus, reduces stress, and increases emotional regulation.\",\n",
    "    \"Take time to rest, set boundaries, and seek support from friends or a professional.\",\n",
    "    \"Offer to listen without judgment and suggest they speak to HR or a mental health counselor.\",\n",
    "    \"Exercise releases endorphins which boost mood, reduce anxiety, and improve sleep.\",\n",
    "    \"Wake up early, maintain consistent sleep times, and schedule time for hobbies.\",\n",
    "    \"Express concern kindly, share resources, and respect their pace and decision.\"\n",
    "]\n",
    "\n",
    "# Create 500 examples\n",
    "data = []\n",
    "for _ in range(500):\n",
    "    q = random.choice(questions)\n",
    "    a = random.choice(answers)\n",
    "    data.append({\"instruction\": q, \"input\": \"\", \"output\": a})\n",
    "\n",
    "# Convert to Huggingface Dataset\n",
    "df = pd.DataFrame(data)\n",
    "mental_health_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Preview\n",
    "mental_health_dataset[0]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CO2vJK3tAIL0",
    "outputId": "95a4cd8b-9cb6-44e2-ab2f-e8d895ef7108"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'instruction': 'How can I deal with anxiety before public speaking?',\n",
       " 'input': '',\n",
       " 'output': 'Offer to listen without judgment and suggest they speak to HR or a mental health counselor.'}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5: Format prompt-response pairs\n",
    "\n",
    "def format_example(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    output = example[\"output\"]\n",
    "    if input_text:\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\"\n",
    "    else:\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    return {\"prompt\": prompt, \"response\": output}\n",
    "\n",
    "formatted_dataset = mental_health_dataset.map(format_example).remove_columns([\"instruction\", \"input\", \"output\"])\n",
    "\n",
    "# Preview\n",
    "formatted_dataset[0]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "cbce7578f33a4627b2ec9932ec11ed3e",
      "06f7bd8bd4f54daab00b6ba370384f19",
      "e850c1d6a6d64a6ebbd224863297fcc4",
      "15c7600eaaca4f769efa4715e2f630da",
      "f887d04b61be4eefaec666a1ff79ae21",
      "5d24eae329f4485cb035087de9a6a6ca",
      "69f0191891744c14bf64cffc41baff8d",
      "fa6878c3101944a3a02c2a6b8ee1bab0",
      "31d3b719414b472d8199c9c44d62dbf7",
      "bd3820f12f9641ceae2d375bd2ff8fb4",
      "497c7c2186474016a208e31ebb0152dc"
     ]
    },
    "id": "PywXovOqAIOj",
    "outputId": "9fc7b769-4c2a-4620-9494-11b8878fee8c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbce7578f33a4627b2ec9932ec11ed3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'prompt': '### Instruction:\\nHow can I deal with anxiety before public speaking?\\n\\n### Response:',\n",
       " 'response': 'Offer to listen without judgment and suggest they speak to HR or a mental health counselor.'}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 6: Fine-tune with SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=formatted_dataset,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=2048,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=2e-5,\n",
    "        fp16=True,\n",
    "        max_steps=100,    # Only 100 steps\n",
    "        logging_steps=10,\n",
    "        output_dir=\"./tinyllama_mentalhealth_finetuned\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        save_strategy=\"epoch\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803,
     "referenced_widgets": [
      "3a35ea879b8749fe83aa93945666813b",
      "9d403d332e90404a8df01c060a4a25a4",
      "dbf898dd965943328939b45163851b83",
      "d20a7f1d637849a9b51971fed14a4974",
      "bd64aeb6c5f249ea8765b08fde61f158",
      "db126a72fdfc4685a6cb66126e15905d",
      "709ecb68824f4c03bc039749ae2a28be",
      "ce6a046d40fd4db4a319ee6267b01dd5",
      "62b54c50a0fe4ad788be2f5870fd4cae",
      "6c14a1c8c5c743e794819a4b5495c066",
      "a4facaed126b4853b5d73ec4e39e39e9"
     ]
    },
    "id": "1vcavXPhAIR8",
    "outputId": "852a11bf-4c5e-437c-fb87-d79563735a42"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"prompt\"] (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a35ea879b8749fe83aa93945666813b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 2 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 4,505,600/4,000,000,000 (0.11% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpomacoc217\u001b[0m (\u001b[33mpomacoc217-college\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250427_160759-td1dvwbq</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pomacoc217-college/huggingface/runs/td1dvwbq' target=\"_blank\">./tinyllama_mentalhealth_finetuned</a></strong> to <a href='https://wandb.ai/pomacoc217-college/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pomacoc217-college/huggingface' target=\"_blank\">https://wandb.ai/pomacoc217-college/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pomacoc217-college/huggingface/runs/td1dvwbq' target=\"_blank\">https://wandb.ai/pomacoc217-college/huggingface/runs/td1dvwbq</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:14, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.948900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=2.411004981994629, metrics={'train_runtime': 98.5881, 'train_samples_per_second': 4.057, 'train_steps_per_second': 1.014, 'total_flos': 58987128987648.0, 'train_loss': 2.411004981994629})"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 7: Save fine-tuned mental health chatbot\n",
    "\n",
    "model.save_pretrained(\"tinyllama_mentalhealth_chatbot\")\n",
    "tokenizer.save_pretrained(\"tinyllama_mentalhealth_chatbot\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NIcM7KcAQSw",
    "outputId": "c480f833-074d-4cba-e77c-87ae720ef7f5"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('tinyllama_mentalhealth_chatbot/tokenizer_config.json',\n",
       " 'tinyllama_mentalhealth_chatbot/special_tokens_map.json',\n",
       " 'tinyllama_mentalhealth_chatbot/tokenizer.model',\n",
       " 'tinyllama_mentalhealth_chatbot/added_tokens.json',\n",
       " 'tinyllama_mentalhealth_chatbot/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 8: Test the chatbot\n",
    "\n",
    "def generate_response(prompt, max_tokens=128):\n",
    "    chat_prompt = f\"### Instruction:\\n{prompt}\\n\\n### Response:\"\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.strip()\n",
    "\n",
    "# Example tests\n",
    "print(\"\\nTest 1:\")\n",
    "print(generate_response(\"How can mindfulness improve mental health?\"))\n",
    "\n",
    "print(\"\\nTest 2:\")\n",
    "print(generate_response(\"What are healthy ways to deal with work stress?\"))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAB6EBfuAQZJ",
    "outputId": "c7121acd-2a84-4f33-cb56-ec7bc0a58f04"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test 1:\n",
      "### Instruction:\n",
      "How can mindfulness improve mental health?\n",
      "\n",
      "### Response:\n",
      "Mindfulness has been shown to have a positive impact on mental health, including reducing symptoms of anxiety and depression. By focusing on the present moment and being fully present in the moment, individuals are better able to manage their thoughts and emotions, leading to improved well-being. Mindfulness also helps to reduce stress and promote relaxation, which can help alleviate symptoms of anxiety and depression. In addition, mindfulness practices such as meditation and yoga have been found to increase self-awareness, which can lead to greater self-compassion and em\n",
      "\n",
      "Test 2:\n",
      "### Instruction:\n",
      "What are healthy ways to deal with work stress?\n",
      "\n",
      "### Response:\n",
      "1. Take breaks - take a break from work and do something that you enjoy, such as reading or taking a walk.\n",
      "2. Practice mindfulness - try meditation or deep breathing exercises to help calm your mind and reduce stress.\n",
      "3. Prioritize self-care - prioritize activities that promote self-care, such as getting enough sleep, eating well, and engaging in hobbies or activities that bring joy.\n",
      "4. Seek support - reach out to friends, family, or a therapist for support during times of stress.\n",
      "5. Stay\n"
     ]
    }
   ]
  }
 ]
}