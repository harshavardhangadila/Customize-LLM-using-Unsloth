{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1YzAzsXJYqrU2wJ3waBiaLAbOJJCuIoZm?usp=sharing\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "id": "OsUahva-MVwy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4A-QwxuMOPy",
    "outputId": "b371e8c3-69ef-404b-8f7e-d6645e297dc8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m506.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install -q unsloth accelerate bitsandbytes datasets einops xformers\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load LLaMA-2-7B in 4-bit using Unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    max_seq_length=512,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "a6d903ff7a6e46c695c07a6b9559ade9",
      "0832c84bfce34662902082f849f89605",
      "ec3793cbed5e4405afe0cb3f2264b916",
      "d7cd8b122ca14e1e9d8e9c9a861c451f",
      "d69e954d92784bd1aec45ac8183955d7",
      "47809de39a4f43fd8141e507e9f85e1f",
      "c9397a701744464196c21e05d43e3b8b",
      "3b9b4291e8a7466b8412d7c4f5aa7c1c",
      "b958eee8092a48479fe084a3c53636c1",
      "d387a98fe9cb4002b3c13fa2579d0b0e",
      "967ffaeba58d4fd9b1759a79a40a2c74",
      "47e835d06aaa4933904b238cc4735690",
      "e1ebea9d4565488c82e34401f3732ef9",
      "ce0f208212514db7b8960fb9fdef1e8c",
      "d7547964689644c1b4856ce1266e195a",
      "71c48906e1264b51bb3a27485a48d3c5",
      "f045a1f289f7456191a9a728f4967519",
      "027f784f9560459ba2ae168e0019b2c8",
      "524916ac2a33400fae6c168a27c96bc8",
      "e2bb15af1bbf4e7eae3d1283ef6283d9",
      "33edc0cee68347a192a5efcd79903c85",
      "77353dee9c93496793a88210dabc5c0f",
      "47e1828fc58d414ab82882b64f98f4d3",
      "5ba0091e9b8e483795ccba5afcd68e40",
      "74cc4e26c88f4557b45584c55548d883",
      "8b67a0039d434fc985774ae2d485b2d5",
      "962cdc3e116943f6883674e3cdc550ec",
      "93c86b219847407297f058aab83c0803",
      "6b481ceeb6914d128a3257195210aa9d",
      "339de3db070d40b39214d9e62a5425ce",
      "6d62fca75fc34a89952a1b1faffbe96b",
      "c71d586472fd4aae9f45e70201a37503",
      "827e55ba35b14e58b6b35d43ae2fbed7",
      "f8892ffa56ec495ab8688f11aa6707de",
      "6a7f4d090a23452e83c402a7235d5f46",
      "f076cf6342b9482b932be7cf91fb08c7",
      "395cf3a3a3b944468a1ed77be3acc8e6",
      "b2c095c725194c929982265b8d6d642e",
      "b29c2480d43b4a9683db2fdd9af74310",
      "263e5880a32f4a968ff55ead1b691347",
      "d939d6553feb4e0ca4fd800943428e81",
      "46198b9bb745499381f52f0e85f20aaa",
      "2446006ce0474e8c9203085563bf5010",
      "fb5fc97d274c444da369ea3f723e5d39",
      "da272a96542845008749432aa351fd63",
      "69dcf812dd694bfa820b01f56d5d7428",
      "de04ff41947744d08018bf191f5ca776",
      "887cdaac6c894389884a8c8ecab00a06",
      "d8931d477f4646f597640431d60e3aff",
      "b7ff1fdd7e1940f2bbef12be0e3d069f",
      "ae506b46b699459db70529cd907ad01a",
      "dba8ad2f61fc40d79777bb8c336021cd",
      "36d78c3d90a34f7eb28bb41c9a0a6f77",
      "8e0f86dfa4fc4974a45bd4b26db8512a",
      "d5b20df5056548f1ad9d1f64b2163364",
      "761a2e151a2b43839d8e2bdf7147b11f",
      "b2226fd92aa14ce186e65d116d4e3c3e",
      "7c6e344986bf4452b3443bf4341f08db",
      "54efe984de96460d98d063e0614bf947",
      "957ba187212f48d88cd2766143592563",
      "ed8d3c395e8648f9a59632c42935db3f",
      "996a456a05d74fcebd80e5f1bf33993a",
      "bc2013bcfd8943ea95c7aed43b9bce06",
      "4122a2dd1e48407b829763e001a783e2",
      "b712944923db4acf9766cda0206d4d6b",
      "f267372c8e6541f6bb450f95c4819970"
     ]
    },
    "id": "HKBhZcsCMjGA",
    "outputId": "301ecf11-8eeb-4a71-fdab-922503f43fdd"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6d903ff7a6e46c695c07a6b9559ade9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e835d06aaa4933904b238cc4735690"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/948 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e1828fc58d414ab82882b64f98f4d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8892ffa56ec495ab8688f11aa6707de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da272a96542845008749432aa351fd63"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "761a2e151a2b43839d8e2bdf7147b11f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Enable LoRA for fine-tuning\n",
    "FastLanguageModel.for_training(model, use_gradient_checkpointing=True)\n",
    "model = FastLanguageModel.get_peft_model(model)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKG_oxK5MjI5",
    "outputId": "c359f344-ddd2-4082-ad61-b01a6325f5c8"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth 2025.4.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load smaller dataset\n",
    "dataset = load_dataset(\"xsum\", split=\"train[:5000]\")\n",
    "\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"text\": f\"### Article:\\n{example['document']}\\n\\n### Summary:\\n{example['summary']}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_example)\n",
    "\n",
    "def tokenize(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "dataset = dataset.map(tokenize, remove_columns=dataset.column_names)\n",
    "\n",
    "# Trainer setup\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinyllama_unsloth_summarizer\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=50,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "# Fast training\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418,
     "referenced_widgets": [
      "a15349e2953042cd854471049d6756e9",
      "2fc09fc14dfe4bc8a8d86805aeb9d27c",
      "699f9d7248ff4983a1b7cc252206b75b",
      "18b2704cd2fe44689132aade4839d32b",
      "b62347cf713c4450b8a4fe759b762048",
      "366497e579234bbb96b3b3d0218e2ed1",
      "22bedce01a144b1f9c7df504ec5ed535",
      "a8370afe5b974dfca13b47532b29b0a2",
      "53e62a63b3434102a163268078d95d22",
      "98075c26ee3145fea8b65ebaf40240f3",
      "4c1cffcc2c4142bca4ac507f1a1e342c",
      "cbc247321fa641d9ab41a016217a8974",
      "3d87c5b0c40647418c423d49771fcbc8",
      "363943b7016f4fbc8779807d1b6c6d70",
      "3e3dfba5211146b4a5e4e3d992a58a5d",
      "3839fb954a974f15bafea88b62daef27",
      "f4e5ae89d9314aaa99330d6547179baa",
      "d4aaf46d46f7468b9969f979906dea44",
      "71deaff7ec814012a931a3c8d0711e8c",
      "7f911c2ca94845288db7c366e94de567",
      "3e5f77760ffc40999b86382ce4c5fc96",
      "0b7d98240b1e4d7691b60424d215ecae"
     ]
    },
    "id": "XwpTjBfxMVL9",
    "outputId": "5c906f5a-c74e-4a54-cad8-b3ddcf1d9423"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a15349e2953042cd854471049d6756e9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbc247321fa641d9ab41a016217a8974"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 5,000 | Num Epochs = 1 | Total steps = 50\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 2 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 39,976,960/7,000,000,000 (0.57% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 04:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.750700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=1.7087652587890625, metrics={'train_runtime': 270.3463, 'train_samples_per_second': 0.74, 'train_steps_per_second': 0.185, 'total_flos': 4084113761894400.0, 'train_loss': 1.7087652587890625, 'epoch': 0.04})"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save trained LoRA adapter\n",
    "model.save_pretrained(\"tinyllama_unsloth_summarizer_lora\")\n",
    "tokenizer.save_pretrained(\"tinyllama_unsloth_summarizer_lora\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snYkUNcCMVOl",
    "outputId": "2ecd355b-263b-4833-d36e-c2fa525510fe"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('tinyllama_unsloth_summarizer_lora/tokenizer_config.json',\n",
       " 'tinyllama_unsloth_summarizer_lora/special_tokens_map.json',\n",
       " 'tinyllama_unsloth_summarizer_lora/tokenizer.model',\n",
       " 'tinyllama_unsloth_summarizer_lora/added_tokens.json',\n",
       " 'tinyllama_unsloth_summarizer_lora/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test model with new unseen articles\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prompt = \"\"\"### Instruction:\n",
    "Summarize the article below in 1\u20132 sentences.\n",
    "\n",
    "### Article:\n",
    "Scientists exploring the remote jungles of the Amazon have discovered a previously unknown species of bird.\n",
    "The newly identified bird is notable for its vibrant, multicolored feathers that shimmer under sunlight.\n",
    "Unlike other related species, this bird produces a unique and melodious call, making it easy to distinguish.\n",
    "Researchers believe the bird has evolved in isolation, adapting to the dense, humid environment of the Amazon.\n",
    "Its discovery highlights the incredible biodiversity that remains hidden within the world's rainforests.\n",
    "Scientists have already begun detailed studies of its behavior, diet, and mating patterns.\n",
    "Preliminary observations suggest it feeds primarily on exotic fruits and small insects.\n",
    "Conservationists are stressing the importance of preserving the bird's fragile habitat from deforestation.\n",
    "This discovery may also shed light on evolutionary patterns among tropical bird species.\n",
    "The scientific community has hailed the find as a major contribution to our understanding of avian diversity.\n",
    "\n",
    "### Summary:\"\"\"\n",
    "\n",
    "inputs2 = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs2 = model.generate(\n",
    "        **inputs2,\n",
    "        max_new_tokens=80,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs2[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dT4e6gL3Mu3Y",
    "outputId": "eb1ae8a7-1c29-4ccc-862b-7ca2b5cb281c"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Instruction:\n",
      "Summarize the article below in 1\u20132 sentences.\n",
      "\n",
      "### Article:\n",
      "Scientists exploring the remote jungles of the Amazon have discovered a previously unknown species of bird.\n",
      "The newly identified bird is notable for its vibrant, multicolored feathers that shimmer under sunlight.\n",
      "Unlike other related species, this bird produces a unique and melodious call, making it easy to distinguish.\n",
      "Researchers believe the bird has evolved in isolation, adapting to the dense, humid environment of the Amazon.\n",
      "Its discovery highlights the incredible biodiversity that remains hidden within the world's rainforests.\n",
      "Scientists have already begun detailed studies of its behavior, diet, and mating patterns.\n",
      "Preliminary observations suggest it feeds primarily on exotic fruits and small insects.\n",
      "Conservationists are stressing the importance of preserving the bird's fragile habitat from deforestation.\n",
      "This discovery may also shed light on evolutionary patterns among tropical bird species.\n",
      "The scientific community has hailed the find as a major contribution to our understanding of avian diversity.\n",
      "\n",
      "### Summary:\n",
      "Scientists have discovered a new species of bird in the remote jungles of the Amazon. The bird is notable for its vibrant, multicolored feathers that shimmer under sunlight. It produces a unique and melodious call, making it easy to distinguish.\n",
      "\n",
      "### Keywords:\n",
      "Scientists, Amazon, Bird, Vibrant, Fe\n"
     ]
    }
   ]
  }
 ]
}