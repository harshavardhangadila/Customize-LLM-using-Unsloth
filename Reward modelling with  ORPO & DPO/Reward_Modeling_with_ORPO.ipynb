{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1RvrnYg5Tpu81hNSnjuLdeF5VWxC_NWRv?usp=sharing\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "id": "yKttxFa-tKZz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Na2z4EHtF-o",
    "outputId": "83733dce-65b6-41f7-8d3c-06e098d0f1ff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "#1 Install libraries\n",
    "!pip install -q unsloth \"torch>=2.1\" transformers peft datasets trl accelerate"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#2 Load TinyLlama with Unsloth\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=True,\n",
    "    random_state=42,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417,
     "referenced_widgets": [
      "29bac616bac44d7c862b20d3835d0b80",
      "f9ded75da4b141ce93fe4da930469c29",
      "2e7c94d85ca04772a931891916651ed0",
      "8a52a90e72914da0a208cb13130d1f15",
      "4079540bab264485bd05a24761cfcc02",
      "824006be63974b9eb2881a806eaac22a",
      "3891649b08914944ad705ee8e12be086",
      "2895bcf05db04e9188568c3641ec7135",
      "09a00d6132634982851e4ecd5643f113",
      "bbf8a5ad3a104938ad940956c5b50688",
      "01e7bb0720d04860b6894a78181f2ab3",
      "72f547fef17446fe80a9e8231df3ce50",
      "f294294b75154ffe8b235b6bfe0deb22",
      "776209814ef74ee0979dcc9d2bdff5b5",
      "c329801ba7574e26b50233768bd68fcb",
      "62b0240c6aa74ac792d65323999b1aa0",
      "887bca67c29a475e823c21c404ae2655",
      "d1767e41c6aa4a78a4d05e419946ccad",
      "f759ab311e904e4d810187c491e3b2e5",
      "53d9d0142dcb4b2494dab96d5eb6b400",
      "94a604bebf8b433c98860138e48f8ed2",
      "706431169cad4ed0b6610f55a64eb718",
      "2497512a6aa846a3a955831168cf2fed",
      "76299cdc57364643a99ef64c8382ef75",
      "f23be163021447f3a7b94c5187339012",
      "72a94e1400e7475b852f24df0016d090",
      "8b5ecfdb014f4d74bca32e3391c69434",
      "f34fedafd78f44cfbe19d19f2be13c3d",
      "4bec6388ab0f4dd4bb5a40d4205db20f",
      "fa2503343a0e43a39de4f4c42a2fe756",
      "c7ba005756414c66b33bd0732eb88edf",
      "33ea8a306f7d4be69d4fb621b11d087d",
      "9b47481173214632b9ac3a94fbd7758f",
      "81f2fb0344f04b59b60ee35be5c64de6",
      "70c2acada99f44c195ab54c1d6f01988",
      "5a1b3cac50af4c1e861a12faa25cae97",
      "7b566cf702ad4e099ba5cf2b7bb47d72",
      "936dcf496c6348c2b6637dae7f58fdaf",
      "4a5aef6f566c4d6080a3f46b049bd289",
      "3bc7fd1c908e47928d29ee952978cb76",
      "d702e7ce7721449ebf5e065d5daff9db",
      "a0100c8257404427bd5c853ccd11d93e",
      "cf95bff515f44b85b4c611b24cfa4910",
      "21db1586a0344dd5a4bd25b67953ae83",
      "0a94d2cef7924c41859d43d37cf02aa7",
      "b84ea40b3e3148e4b6ec6db6aa44f646",
      "30cff4533912496f8fc8d3fd49926db8",
      "b23aafbe98374ff9873defb43a187387",
      "cb611c1f9c134e4e83fb3ce078de284d",
      "5a15c734b6b74cf886d7ec4debd5a34c",
      "0986f22d68c341c9ba172d21e6a37621",
      "e8a453dcd8c54400b6b1af4629a16cfc",
      "b90bc7c8dddd4a1689e3b03dcf4f0722",
      "1d0b1f340eae4dd7b1e2970a435013f0",
      "91dbe3aee6cd4d04a83affb202d737c0",
      "0104cb6fc7a043d7a6f63a115f49f318",
      "5668d96fdeb94a5fba011ffb513d03fb",
      "0cde409b2c6b407c8646cedbf457660f",
      "d88e2b7a73fc40c5b9d323ea44a50feb",
      "2e0486a809b54ba891c1fd5fdf44a24a",
      "5da01435d7b24c2ebbfd800a6cda7d52",
      "fc8b85712c0148f1b9966ec2b83acd48",
      "6b5c7ba1555b4f85af546f9796f0467d",
      "9451d2cf2e5c4936bf2a0bd66c4c4327",
      "67236cb48c8d415a980c9ab544a2cae9",
      "e48de81253ca4fafafbf8c9ad1fc6685"
     ]
    },
    "id": "ZMCLHwOatJ-3",
    "outputId": "2096a380-09dc-4a82-d243-1bc45ff616f5"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/762M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29bac616bac44d7c862b20d3835d0b80"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f547fef17446fe80a9e8231df3ce50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2497512a6aa846a3a955831168cf2fed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81f2fb0344f04b59b60ee35be5c64de6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a94d2cef7924c41859d43d37cf02aa7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0104cb6fc7a043d7a6f63a115f49f318"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.4.1 patched 22 layers with 22 QKV layers, 22 O layers and 0 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#3 Load and prepare OpenAssistant dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Intel/orca_dpo_pairs\", split=\"train[:10000]\")\n",
    "\n",
    "def format_orpo(example):\n",
    "    return {\n",
    "        \"prompt\": f\"<|im_start|>user\\n{example['question']}\\n<|im_end|>\",\n",
    "        \"chosen\": f\"<|im_start|>assistant\\n{example['chosen']}\\n<|im_end|>\",\n",
    "        \"rejected\": f\"<|im_start|>assistant\\n{example['rejected']}\\n<|im_end|>\",\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_orpo)\n",
    "print(f\" Final usable examples: {len(dataset)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "8349961ad4fa4b54bbfe8240aef33182",
      "11b4d415ee8c4ca89bbdddb111e33eea",
      "4464d2a758f34ff4b36dcec28f3113c2",
      "d4a7899dc73b4d79b0d37387441cb8a6",
      "680a1dd5f770483b8603cada76eff647",
      "7679618690b74580b6becdc890ec8e35",
      "60562261adbf483692bf7307a3ab4811",
      "6c83b8bb4a3d48789dfa10e18e43e1a7",
      "fd2b1f4c08ae4ddea03459abf1299c5b",
      "55be6fb263fb4ab3bc22d3a741251eec",
      "a299ebd9eb4848879bad7f53aaa57fc3",
      "7e396645f1964d68ac7b9fb360741ea4",
      "4c8c536422474d1fb417a0119257e992",
      "723899bc1d0340ca812fe1f09d6b8351",
      "4cd983927223413393f0621accb5b1b4",
      "4716709016364c0cbd39c56ac327d90f",
      "e31b224da91347f38955b70f0c9885fa",
      "8a7d79a188b9476caeb756fe1ac24ce7",
      "b4afc53bbd384fe980c9f829b0e9f4f9",
      "aa15a3fcba9e4d169d61fac9b92702ae",
      "20192f1b39dd42cf86ec9e434f6616a5",
      "b8b8991681944c348d5f1ce7ce51af57",
      "8639a6f0015a432782c82f8f567aae8a",
      "5bfdcae680154dac976cff7796b9649e",
      "f90df5ed034045a887ebee281c3b1e41",
      "e26e63e0978f4295a5d23d021b99d4db",
      "27bc8c4f950148a492fcc28ae9489c14",
      "ab4e8f5028184cddb89fb143ad6efe8c",
      "e89a53b968174846b1b1bc42622ef8b2",
      "d246bcf33ac546aa81eafd5d27564072",
      "73551ecb54314003abe895f60e73c657",
      "7f47a6079dcc4a0daf57c019ba6e096d",
      "20fdc6b827214fc0bb2703e90a3b1a1d",
      "2c7f7651134342eb96601db50dc0b974",
      "e2b8bb9f9b2c4937953418fb1f37e39f",
      "1b0c1f7cb57540208386e834662c10dd",
      "7415939092ba4302ab1e1a47bc816109",
      "dec545414ded4534947023663b4af0cb",
      "797622a71ddf40369b26389c9dcf0e7a",
      "19e556328e154d3a9c830a7e4d62232d",
      "c90015071b204eaab6a79524fff55b82",
      "e60a061a41714cc597a91e84019a8df6",
      "b1dc95e0fe0845728c430d161ac8fcd2",
      "81c5f5091ea4444f98bdea7fc62fd2ae"
     ]
    },
    "id": "z3q__C1ztKBX",
    "outputId": "b93903fb-caee-40f0-ba8e-9115395f698e"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/196 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8349961ad4fa4b54bbfe8240aef33182"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "orca_rlhf.jsonl:   0%|          | 0.00/36.3M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e396645f1964d68ac7b9fb360741ea4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/12859 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8639a6f0015a432782c82f8f567aae8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c7f7651134342eb96601db50dc0b974"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Final usable examples: 10000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#4 Train model using ORPOTrainer\n",
    "\n",
    "from trl import ORPOTrainer, ORPOConfig\n",
    "\n",
    "config = ORPOConfig(\n",
    "    output_dir=\"tinyllama-orpo-intel\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=100,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=config,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "id": "VQ6CRNCftZ_X",
    "outputId": "6ecbb43b-cdcf-4595-b5ba-bc4c24a5b43d"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/content/unsloth_compiled_cache/UnslothORPOTrainer.py:552: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10,000 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 2 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 4,505,600/4,000,000,000 (0.11% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 03:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "      <th>log_odds_ratio</th>\n",
       "      <th>log_odds_chosen</th>\n",
       "      <th>eval_logits / chosen</th>\n",
       "      <th>eval_logits / rejected</th>\n",
       "      <th>nll_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.541600</td>\n",
       "      <td>-0.151917</td>\n",
       "      <td>-0.127412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.024506</td>\n",
       "      <td>-1.274118</td>\n",
       "      <td>-1.519174</td>\n",
       "      <td>-2.868562</td>\n",
       "      <td>-2.348754</td>\n",
       "      <td>-0.921773</td>\n",
       "      <td>-0.338389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.178645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.243200</td>\n",
       "      <td>-0.133449</td>\n",
       "      <td>-0.132883</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>-1.328834</td>\n",
       "      <td>-1.334485</td>\n",
       "      <td>-2.754775</td>\n",
       "      <td>-2.162274</td>\n",
       "      <td>-0.722439</td>\n",
       "      <td>-0.031018</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.049347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.229700</td>\n",
       "      <td>-0.123110</td>\n",
       "      <td>-0.101236</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.021875</td>\n",
       "      <td>-1.012358</td>\n",
       "      <td>-1.231104</td>\n",
       "      <td>-2.749705</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>-0.881840</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.026656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.250500</td>\n",
       "      <td>-0.132226</td>\n",
       "      <td>-0.110777</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.021449</td>\n",
       "      <td>-1.107770</td>\n",
       "      <td>-1.322261</td>\n",
       "      <td>-2.742855</td>\n",
       "      <td>-2.007662</td>\n",
       "      <td>-0.908862</td>\n",
       "      <td>-0.317451</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.034378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4.073100</td>\n",
       "      <td>-0.137863</td>\n",
       "      <td>-0.120095</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.017768</td>\n",
       "      <td>-1.200948</td>\n",
       "      <td>-1.378632</td>\n",
       "      <td>-2.730704</td>\n",
       "      <td>-2.231710</td>\n",
       "      <td>-0.851312</td>\n",
       "      <td>-0.250119</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.951403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.766100</td>\n",
       "      <td>-0.122067</td>\n",
       "      <td>-0.106222</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>-1.062222</td>\n",
       "      <td>-1.220667</td>\n",
       "      <td>-2.778332</td>\n",
       "      <td>-2.222068</td>\n",
       "      <td>-0.849646</td>\n",
       "      <td>-0.224033</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.798106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>4.009700</td>\n",
       "      <td>-0.105807</td>\n",
       "      <td>-0.107686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>-1.076860</td>\n",
       "      <td>-1.058066</td>\n",
       "      <td>-2.879885</td>\n",
       "      <td>-2.145356</td>\n",
       "      <td>-0.712566</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.933595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.993600</td>\n",
       "      <td>-0.111040</td>\n",
       "      <td>-0.109305</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.001735</td>\n",
       "      <td>-1.093053</td>\n",
       "      <td>-1.110400</td>\n",
       "      <td>-2.777297</td>\n",
       "      <td>-2.224131</td>\n",
       "      <td>-0.763974</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.920423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.923900</td>\n",
       "      <td>-0.108816</td>\n",
       "      <td>-0.101106</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>-1.011056</td>\n",
       "      <td>-1.088161</td>\n",
       "      <td>-2.545233</td>\n",
       "      <td>-2.193883</td>\n",
       "      <td>-0.765895</td>\n",
       "      <td>-0.084685</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.885375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.955000</td>\n",
       "      <td>-0.096360</td>\n",
       "      <td>-0.100671</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>-1.006710</td>\n",
       "      <td>-0.963595</td>\n",
       "      <td>-2.623728</td>\n",
       "      <td>-2.176910</td>\n",
       "      <td>-0.678008</td>\n",
       "      <td>0.135495</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.909693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>4.144900</td>\n",
       "      <td>-0.138298</td>\n",
       "      <td>-0.111302</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.026997</td>\n",
       "      <td>-1.113016</td>\n",
       "      <td>-1.382984</td>\n",
       "      <td>-2.603964</td>\n",
       "      <td>-1.940415</td>\n",
       "      <td>-0.937466</td>\n",
       "      <td>-0.328205</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.978698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.831500</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>-0.105920</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>-1.059199</td>\n",
       "      <td>-1.085881</td>\n",
       "      <td>-2.462268</td>\n",
       "      <td>-1.666886</td>\n",
       "      <td>-0.761869</td>\n",
       "      <td>-0.024641</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.839573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.545900</td>\n",
       "      <td>-0.109691</td>\n",
       "      <td>-0.117617</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>-1.176173</td>\n",
       "      <td>-1.096908</td>\n",
       "      <td>-2.729161</td>\n",
       "      <td>-1.988944</td>\n",
       "      <td>-0.684968</td>\n",
       "      <td>0.158056</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.704430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.476500</td>\n",
       "      <td>-0.092700</td>\n",
       "      <td>-0.094928</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>-0.949276</td>\n",
       "      <td>-0.927000</td>\n",
       "      <td>-2.471703</td>\n",
       "      <td>-2.006881</td>\n",
       "      <td>-0.704047</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.667832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.618500</td>\n",
       "      <td>-0.119374</td>\n",
       "      <td>-0.104554</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.014820</td>\n",
       "      <td>-1.045542</td>\n",
       "      <td>-1.193737</td>\n",
       "      <td>-2.409672</td>\n",
       "      <td>-2.259116</td>\n",
       "      <td>-0.839426</td>\n",
       "      <td>-0.183955</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.725294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.483300</td>\n",
       "      <td>-0.106052</td>\n",
       "      <td>-0.117053</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>-1.170527</td>\n",
       "      <td>-1.060521</td>\n",
       "      <td>-2.745454</td>\n",
       "      <td>-2.134398</td>\n",
       "      <td>-0.665383</td>\n",
       "      <td>0.254213</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.675132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.211400</td>\n",
       "      <td>-0.095034</td>\n",
       "      <td>-0.103557</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>-1.035574</td>\n",
       "      <td>-0.950336</td>\n",
       "      <td>-2.276025</td>\n",
       "      <td>-2.005904</td>\n",
       "      <td>-0.676361</td>\n",
       "      <td>0.190773</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.538074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.651400</td>\n",
       "      <td>-0.088888</td>\n",
       "      <td>-0.105984</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.017096</td>\n",
       "      <td>-1.059838</td>\n",
       "      <td>-0.888877</td>\n",
       "      <td>-2.662821</td>\n",
       "      <td>-2.352537</td>\n",
       "      <td>-0.613318</td>\n",
       "      <td>0.416376</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.764368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.563700</td>\n",
       "      <td>-0.114642</td>\n",
       "      <td>-0.093851</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.020790</td>\n",
       "      <td>-0.938514</td>\n",
       "      <td>-1.146416</td>\n",
       "      <td>-2.842547</td>\n",
       "      <td>-2.368448</td>\n",
       "      <td>-0.908085</td>\n",
       "      <td>-0.301287</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.691032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.491600</td>\n",
       "      <td>-0.098513</td>\n",
       "      <td>-0.099744</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>-0.997435</td>\n",
       "      <td>-0.985126</td>\n",
       "      <td>-2.665129</td>\n",
       "      <td>-2.335242</td>\n",
       "      <td>-0.757608</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>1.670033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.8502572441101073, metrics={'train_runtime': 203.8676, 'train_samples_per_second': 1.962, 'train_steps_per_second': 0.491, 'total_flos': 0.0, 'train_loss': 3.8502572441101073, 'epoch': 0.04})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#5 Define generation function\n",
    "\n",
    "def generate_response(prompt, max_tokens=128):\n",
    "    chat_prompt = f\"<|im_start|>user\\n{prompt}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()"
   ],
   "metadata": {
    "id": "28uaeGyOuEws"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 6: Test the fine-tuned ORPO model with clean prompts\n",
    "\n",
    "def generate_response(prompt, max_tokens=128):\n",
    "    chat_prompt = f\"<|im_start|>user\\n{prompt}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()\n",
    "\n",
    "# Test different prompts\n",
    "print(\"Test 1:\")\n",
    "print(generate_response(\"Can you explain quantum mechanics in basic terms?\"))\n",
    "\n",
    "print(\"\\nTest 2:\")\n",
    "print(generate_response(\"List three benefits of exercising daily.\"))\n",
    "\n",
    "\n",
    "print(\"\\nTest 3:\")\n",
    "print(generate_response(\"How do airplanes stay in the air despite being so heavy?\"))\n",
    "\n",
    "print(\"\\nTest 4:\")\n",
    "print(generate_response(\"What are some healthy snacks I can eat during work?\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYiDTF9suEz4",
    "outputId": "8496502f-8ee7-4c61-ed0e-50cf8e0504f8"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test 1:\n",
      "Sure! Quantum mechanics is a branch of physics that deals with the behavior of matter and energy at the smallest scales, known as the quantum level. It is a branch of physics that is based on the principles of quantum mechanics, which are the laws that govern the behavior of particles at the smallest scales.\n",
      "\n",
      "Quantum mechanics is a fundamental theory that describes the behavior of particles at the smallest scales, known as the quantum level. It is based on the principles of quantum mechanics, which are the laws that govern the behavior of particles at the smallest scales.\n",
      "\n",
      "Quantum mechanics is a branch of\n",
      "\n",
      "Test 2:\n",
      "1. Increased energy levels: Regular exercise helps to increase energy levels, which can help you to feel more alert and focused throughout the day.\n",
      "\n",
      "2. Improved mood: Exercise has been shown to have a positive impact on mood, reducing symptoms of depression and anxiety.\n",
      "\n",
      "3. Reduced stress: Regular exercise can help to reduce stress levels, which can have a positive impact on mental health.\n",
      "\n",
      "Remember to always consult with a healthcare professional before starting any new exercise routine, especially if you have any pre-existing medical conditions.\n",
      "\n",
      "Test 3:\n",
      "Airplanes are heavier than air because they are made of materials that are denser than air. The denser materials, such as aluminum, steel, and composite materials, are stronger and more durable than air. They are also lighter than air, which means that they can float on it.\n",
      "\n",
      "The airplane's wings are designed to generate lift, which is the force that keeps the plane in the air. The wings are made of thin, lightweight materials such as aluminum, which are stronger than air. The airplane's wings are designed to be curved, which allows\n",
      "\n",
      "Test 4:\n",
      "Sure, here are some healthy snacks you can eat during work:\n",
      "\n",
      "1. Fresh fruit: Apples, bananas, oranges, grapes, and berries are all great options.\n",
      "\n",
      "2. Nuts and seeds: Almonds, cashews, pumpkin seeds, and sunflower seeds are all great options.\n",
      "\n",
      "3. Hummus and veggies: Hummus with carrots, cucumbers, and bell peppers is a great snack.\n",
      "\n",
      "4. Yogurt and fruit: Greek yogurt with\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 7: Save the fine-tuned TinyLlama ORPO model\n",
    "\n",
    "model.save_pretrained(\"tinyllama_orpo_intel\")\n",
    "tokenizer.save_pretrained(\"tinyllama_orpo_intel\")\n",
    "\n",
    "print(\"Fine-tuned ORPO model saved successfully.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqH6GlpQuE3L",
    "outputId": "24e09175-ac61-4645-c85e-d1e49dc91a5d"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-tuned ORPO model saved successfully.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 8: Reload the saved fine-tuned TinyLlama ORPO model\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "reloaded_model, reloaded_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"tinyllama_orpo_intel\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "print(\"Model and tokenizer reloaded successfully.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LVsFjw9taCS",
    "outputId": "57564f76-6d42-4257-b0d9-05dc13281df5"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Model and tokenizer reloaded successfully.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 9: Test the reloaded model on new prompts\n",
    "\n",
    "def generate_response_reload(prompt, max_tokens=128):\n",
    "    chat_prompt = f\"<|im_start|>user\\n{prompt}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    inputs = reloaded_tokenizer(chat_prompt, return_tensors=\"pt\").to(reloaded_model.device)\n",
    "    outputs = reloaded_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=reloaded_tokenizer.eos_token_id,\n",
    "    )\n",
    "    decoded = reloaded_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()\n",
    "\n",
    "# New unseen questions\n",
    "print(\"New Test 1:\")\n",
    "print(generate_response_reload(\"How does gravity work in space?\"))\n",
    "\n",
    "print(\"\\nNew Test 2:\")\n",
    "print(generate_response_reload(\"What are the main ingredients of a healthy salad?\"))\n",
    "\n",
    "print(\"\\nNew Test 3:\")\n",
    "print(generate_response_reload(\"Explain why we have seasons on Earth.\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2buy9AgqtaFH",
    "outputId": "3b446946-be65-4df9-836e-7179e9bb9e13"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New Test 1:\n",
      "Gravity in space is different from gravity on Earth. In space, gravity is caused by the curvature of space-time, which is caused by the mass of objects in space. The curvature of space-time is caused by the mass of objects in space, which is called the gravitational field.\n",
      "\n",
      "In space, gravity is weaker than on Earth because there is no mass to distort space-time. Instead, the gravitational field is caused by the mass of objects in space. The mass of objects in space is called the gravitational field.\n",
      "\n",
      "The gravitational field is caused by the mass of\n",
      "\n",
      "New Test 2:\n",
      "The main ingredients of a healthy salad are:\n",
      "1. Leafy greens such as spinach, kale, or collard greens.\n",
      "2. Fresh vegetables such as carrots, bell peppers, cucumbers, and tomatoes.\n",
      "3. Nuts and seeds such as almonds, pumpkin seeds, or sunflower seeds.\n",
      "4. Dairy products such as low-fat or non-fat milk, yogurt, or cheese.\n",
      "5. Fat-free or low-fat\n",
      "\n",
      "New Test 3:\n",
      "The Earth has seasons because it is a planet that orbits around the Sun. The Sun is a star that emits heat energy that causes the Earth's atmosphere to warm up. This warming causes the Earth's surface to become more or less hospitable for life.\n",
      "\n",
      "The seasons are caused by the Earth's rotation around the Sun. The Earth spins on its axis once every 23 hours, 56 minutes, and 480 seconds. This rotation causes the Earth's surface to be tilted at an angle of 23.5 degrees relative to the plane of the Earth\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 10: Analyze the output length for generated responses\n",
    "\n",
    "prompts = [\n",
    "    \"Explain how the water cycle works.\",\n",
    "    \"Give three tips to stay productive while working remotely.\",\n",
    "    \"Describe the invention of the telephone in simple words.\"\n",
    "]\n",
    "\n",
    "for idx, prompt in enumerate(prompts, start=1):\n",
    "    response = generate_response_reload(prompt)\n",
    "    num_tokens = len(reloaded_tokenizer.tokenize(response))\n",
    "    print(f\"\\nPrompt {idx} generated response with {num_tokens} tokens.\")\n",
    "    print(response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6UZMzVbtaH3",
    "outputId": "10a937aa-2bae-4761-a013-9a9f9861fcce"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Prompt 1 generated response with 126 tokens.\n",
      "The water cycle is a complex process that involves the movement of water from one form to another. It is a fundamental process in the Earth's ecosystem, and it is essential for the survival of life on Earth.\n",
      "\n",
      "The water cycle is divided into three main stages: evaporation, condensation, and precipitation. Evaporation is the process by which water vapor (usually in the form of water droplets) is converted into water molecules. This process occurs when the temperature of the Earth's surface rises, causing the water vapor to rise into the atmosphere.\n",
      "\n",
      "Prompt 2 generated response with 129 tokens.\n",
      "1. Set boundaries: Set specific times for work and avoid working outside of those hours.\n",
      "\n",
      "2. Prioritize tasks: Prioritize tasks based on their importance and urgency.\n",
      "\n",
      "3. Use productivity tools: Use productivity tools like time-tracking apps, task management apps, and productivity software to help you stay on track.\n",
      "\n",
      "4. Stay connected: Stay connected with colleagues and clients through video conferencing, instant messaging, and other communication tools.\n",
      "\n",
      "5. Take breaks: Take breaks to stretch, walk around, or do something else to help you recharge\n",
      "\n",
      "Prompt 3 generated response with 128 tokens.\n",
      "The invention of the telephone is a significant milestone in the history of communication. It was a breakthrough in the field of telecommunications, which revolutionized the way people communicated with each other. The telephone was invented by Alexander Graham Bell in 1876, and it was a significant step towards the development of modern communication technology.\n",
      "\n",
      "The telephone was a device that allowed people to communicate with each other over long distances. It was a revolutionary invention as it allowed people to make phone calls without having to physically meet each other. The telephone was a significant breakthrough as it\n"
     ]
    }
   ]
  }
 ]
}