{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/drive/10c1amlVfvev7ovrD3iOXjv7UNZXVEA8o?usp=sharing\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "id": "Z4bnl0Ue5By3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#1 Install necessary libraries\n",
    "!pip install -q unsloth \"torch>=2.1\" transformers peft datasets trl accelerate\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdM4rlba5BfJ",
    "outputId": "7fa9caf4-fc0f-44cd-b80d-e174c90e4952"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Import necessary libraries\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wclN2SHC5Bhv",
    "outputId": "5105ca4f-1526-4772-d9ef-bdf96bd8b30b"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3A: Load TinyLlama Model\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=True,\n",
    "    random_state=42,\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "41e1722bb01247d885b37d5402861744",
      "3a6c754b0cb247e0bad5bfc3b27ac5d5",
      "ddf18012e546496db0859008a8c1007c",
      "abc7d65d8571434f8cdccc0582b57177",
      "db1631cf51ea4b1ba1802cc2b3070db3",
      "13380a1146cb45938b2654b149629111",
      "ad50b7cf36084818926a11ec34749ccd",
      "d12be927bc374c2288b5323898884b13",
      "eba18316b7ec41808a49e84ece78b33d",
      "6b04152eef7547e7b721d3523fbfcd85",
      "b52cc1a6530340139cc38a38853f21f5",
      "a0a4ceede3684c7e9296d7977ad50b56",
      "e77c8ae8a81d4c9ba9b83034625f7f66",
      "5782ad97f09e4533858ced44fa007055",
      "a79fa030ba244b52b7a1e7fe6cd06299",
      "33b3ed171c704c32b6de5f1d3dfd771a",
      "acf8bc11219c4c708af6e21d68505212",
      "c1cd3f750c8b41bba00a0b6d70679206",
      "a84dc88d40654d988507cdd321508ef3",
      "aa86e55a954a4d7eaab38d11e7c8d3aa",
      "2da0a332ba1148f9b534a5e886d8269e",
      "be9bcee01bb94ecaa3f21d04f8c2f0c4",
      "6a26a199d8be4fd49ec58aea0412dc9c",
      "d2da6e85fa25415f8643d840fca21e91",
      "8b8e76ac3c0041daab17a058a9e2c407",
      "5984fec1497942aaafb3238d7f715b18",
      "1428f6ec45b1405f8116e51edd96cc13",
      "b7eef8fee7a24ac785959a319a2d9799",
      "502a6def06c54d3483b290f8140c9cce",
      "37a851a7667f410fa0b06dafbf7ed9b5",
      "1ffe6720a16f44b7ac56dcb0e1a38901",
      "924c422b963c40e38a69510240d2910e",
      "deca49aa1e4e41f38a01b9e7c5a23294",
      "9df1f959867a432695039243f8e610f2",
      "634462740ebd4fcc9a83fd21947d0f84",
      "8298a4eeae254f88b6406ec513a2a6de",
      "1eeee3251e9b45bd998cfde7a8c49fda",
      "1b63fe192ad04a899001661e8aa13d2f",
      "96ece3b0df6d4820839400578ab6358b",
      "fc4ad40c358c4df2aab3087913a888d3",
      "7300dfa7925a455389863ebd375a9b40",
      "6a3cba1b6cdc4b848a392809b7a9e052",
      "9023538c3343412fa696b34318ee920a",
      "6d327cadc28f42ad861c435c505b1d46",
      "3014ac86a27746a8b9d24b3cdcbabebb",
      "ff65e32221b34376979537a76cd9ee51",
      "855b783a9bbb47f09c7fb6ab6ebb52aa",
      "75536ac36f4f49dcabd2806ebb4f813f",
      "bac108ac1696487284b219cfb94e643e",
      "61b33aa7988b4bdabca62c38565c4b32",
      "6b07b769efeb4c7599ba6be95b5ec87f",
      "74ed1965014d425ca350fd30a5d8a836",
      "8c34b1e3b0ca4b259d24b0c3b28acb61",
      "1a86710f47244da9be608eaea9b668db",
      "f4d3fe2faac945ea852bfa18cd7510bb",
      "ba3751e10fd94c5d8239de36e1ebfb0b",
      "332f34753b4c48f0ab5a915d519ba037",
      "517f341682674f87b0774dc55b5b9a93",
      "2c9ac87024614ac7bc6bcd2c2ad6a090",
      "61d34b0e64784e1daf888955f661b92d",
      "7b3aeda1a4774f1e9ecd3cea133bd7a2",
      "59eb2453351c4957b5100c673c35c7a2",
      "8dfae43c2e964db8845ce1f385b5d723",
      "4169d5ce6bf64b92a5ff6a4f44e27a38",
      "91ba6054f87942728a8cb66cecf919c1",
      "8cad75073b0e4aa4a39607541064733c"
     ]
    },
    "id": "nsiPR5225Bkv",
    "outputId": "a46ac1d5-494c-4c5e-ffb8-507c59e56d0a"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/762M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e1722bb01247d885b37d5402861744"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0a4ceede3684c7e9296d7977ad50b56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a26a199d8be4fd49ec58aea0412dc9c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9df1f959867a432695039243f8e610f2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3014ac86a27746a8b9d24b3cdcbabebb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba3751e10fd94c5d8239de36e1ebfb0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.4.1 patched 22 layers with 22 QKV layers, 22 O layers and 0 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3B: General knowledge fine-tuning data\n",
    "\n",
    "general_knowledge = [\n",
    "    {\"text\": \"User: What is the boiling point of water?\\nAssistant: Water boils at 100 degrees Celsius at standard pressure.\"},\n",
    "    {\"text\": \"User: Who discovered gravity?\\nAssistant: Sir Isaac Newton is credited with the discovery of gravity.\"},\n",
    "    {\"text\": \"User: What is the capital of France?\\nAssistant: Paris is the capital city of France.\"},\n",
    "    {\"text\": \"User: How many continents are there?\\nAssistant: There are seven continents on Earth.\"},\n",
    "    {\"text\": \"User: What gas do plants use for photosynthesis?\\nAssistant: Plants use carbon dioxide for photosynthesis.\"},\n",
    "    {\"text\": \"User: What is the square root of 64?\\nAssistant: The square root of 64 is 8.\"},\n",
    "    {\"text\": \"User: Who painted the Mona Lisa?\\nAssistant: Leonardo da Vinci painted the Mona Lisa.\"},\n",
    "    {\"text\": \"User: What is the fastest land animal?\\nAssistant: The cheetah is the fastest land animal.\"},\n",
    "    {\"text\": \"User: What is the currency of Japan?\\nAssistant: The currency of Japan is the Yen.\"},\n",
    "    {\"text\": \"User: What organ pumps blood through the body?\\nAssistant: The heart pumps blood through the body.\"},\n",
    "    {\"text\": \"User: Who was the first person to walk on the Moon?\\nAssistant: Neil Armstrong was the first person to walk on the Moon.\"},\n",
    "    {\"text\": \"User: How many sides does a hexagon have?\\nAssistant: A hexagon has six sides.\"},\n",
    "    {\"text\": \"User: What is the process of water turning into vapor called?\\nAssistant: It is called evaporation.\"},\n",
    "    {\"text\": \"User: What metal is liquid at room temperature?\\nAssistant: Mercury is liquid at room temperature.\"},\n",
    "    {\"text\": \"User: What is the main ingredient in guacamole?\\nAssistant: Avocado is the main ingredient in guacamole.\"},\n",
    "    {\"text\": \"User: How many legs does a spider have?\\nAssistant: A spider has eight legs.\"},\n",
    "    {\"text\": \"User: What is the largest mammal?\\nAssistant: The blue whale is the largest mammal.\"},\n",
    "    {\"text\": \"User: What gas do humans need to breathe?\\nAssistant: Humans need oxygen to breathe.\"},\n",
    "    {\"text\": \"User: How many days are in a leap year?\\nAssistant: A leap year has 366 days.\"},\n",
    "    {\"text\": \"User: What is the freezing point of water?\\nAssistant: Water freezes at 0 degrees Celsius.\"},\n",
    "    {\"text\": \"User: What color is chlorophyll?\\nAssistant: Chlorophyll is green.\"},\n",
    "    {\"text\": \"User: Which planet is known as the Red Planet?\\nAssistant: Mars is known as the Red Planet.\"},\n",
    "    {\"text\": \"User: What is the chemical symbol for gold?\\nAssistant: The chemical symbol for gold is Au.\"},\n",
    "    {\"text\": \"User: How many bones are there in the adult human body?\\nAssistant: There are 206 bones in the adult human body.\"},\n",
    "    {\"text\": \"User: Who wrote the play 'Romeo and Juliet'?\\nAssistant: William Shakespeare wrote 'Romeo and Juliet'.\"},\n",
    "    {\"text\": \"User: What is the largest ocean on Earth?\\nAssistant: The Pacific Ocean is the largest ocean on Earth.\"},\n",
    "    {\"text\": \"User: What type of animal is a Komodo dragon?\\nAssistant: A Komodo dragon is a species of lizard.\"},\n",
    "    {\"text\": \"User: What is the capital city of Canada?\\nAssistant: Ottawa is the capital city of Canada.\"},\n",
    "    {\"text\": \"User: What is H2O commonly known as?\\nAssistant: H2O is commonly known as water.\"},\n",
    "    {\"text\": \"User: How many hours are there in a day?\\nAssistant: There are 24 hours in a day.\"},\n",
    "    {\"text\": \"User: What is the smallest planet in our solar system?\\nAssistant: Mercury is the smallest planet in our solar system.\"},\n",
    "    {\"text\": \"User: Who invented the telephone?\\nAssistant: Alexander Graham Bell invented the telephone.\"},\n",
    "    {\"text\": \"User: What shape has three sides?\\nAssistant: A triangle has three sides.\"},\n",
    "    {\"text\": \"User: What is the chemical formula for table salt?\\nAssistant: The chemical formula for table salt is NaCl.\"},\n",
    "    {\"text\": \"User: What is the tallest mountain in the world?\\nAssistant: Mount Everest is the tallest mountain in the world.\"},\n",
    "    {\"text\": \"User: What is the main language spoken in Brazil?\\nAssistant: Portuguese is the main language spoken in Brazil.\"},\n",
    "    {\"text\": \"User: What is the process by which plants make food?\\nAssistant: Photosynthesis is the process by which plants make food.\"},\n",
    "    {\"text\": \"User: What is the hottest planet in our solar system?\\nAssistant: Venus is the hottest planet in our solar system.\"},\n",
    "    {\"text\": \"User: What is the name of the fairy in Peter Pan?\\nAssistant: Tinker Bell is the fairy in Peter Pan.\"},\n",
    "    {\"text\": \"User: Who wrote 'The Origin of Species'?\\nAssistant: Charles Darwin wrote 'The Origin of Species'.\"},\n",
    "    {\"text\": \"User: What is the process of a caterpillar becoming a butterfly called?\\nAssistant: It is called metamorphosis.\"},\n",
    "    {\"text\": \"User: Which element has the chemical symbol O?\\nAssistant: Oxygen has the chemical symbol O.\"},\n",
    "    {\"text\": \"User: What is the main ingredient in bread?\\nAssistant: Flour is the main ingredient in bread.\"},\n",
    "    {\"text\": \"User: How many rings are there on the Olympic flag?\\nAssistant: There are five rings on the Olympic flag.\"},\n",
    "    {\"text\": \"User: What device measures temperature?\\nAssistant: A thermometer measures temperature.\"},\n",
    "    {\"text\": \"User: What is the center of an atom called?\\nAssistant: The center of an atom is called the nucleus.\"},\n",
    "    {\"text\": \"User: What is the chemical symbol for iron?\\nAssistant: The chemical symbol for iron is Fe.\"},\n",
    "    {\"text\": \"User: What part of the plant conducts photosynthesis?\\nAssistant: The leaves conduct photosynthesis.\"},\n",
    "    {\"text\": \"User: Who was the first President of the United States?\\nAssistant: George Washington was the first President of the United States.\"},\n",
    "    {\"text\": \"User: What do bees collect from flowers?\\nAssistant: Bees collect nectar from flowers.\"}\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(general_knowledge)\n",
    "\n",
    "def format_prompt(example):\n",
    "    user_part, assistant_part = example[\"text\"].split(\"Assistant:\")\n",
    "    return {\n",
    "        \"text\": f\"<|im_start|>user\\n{user_part.replace('User:', '').strip()}\\n<|im_end|>\\n<|im_start|>assistant\\n{assistant_part.strip()}\\n<|im_end|>\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_prompt)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1056fda9afaf4394b1789cab678e8447",
      "e0bdbb6f62ba4fea9c8b67c2d7e8c56f",
      "c92a7e57254949bbb82769975f47e6d4",
      "58915a8969f247159dbd45d75d247827",
      "88380576295b4880b7c8f16fe286b7e2",
      "e366e2a7ad4343f4b0c0ba41609a65fa",
      "2f3b3ecd71574a2685b0d50cb0d6face",
      "5e8669582f2043bca4dba45c02ecf03e",
      "ec773febd81e41ebae8c6074b5b48c8f",
      "5ce5c893041347df8069ca32fac4fe48",
      "14bae766efcf452690336f25aef50f5f"
     ]
    },
    "id": "hAQ1aJgI5BnJ",
    "outputId": "388eab12-25fb-4cb1-a972-bcdb3207e0f2"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1056fda9afaf4394b1789cab678e8447"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3C: Initial fine-tuning\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sft-initial-checkpoint\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=100,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856,
     "referenced_widgets": [
      "6690e407e6e645f28e83bbb122750420",
      "9a48275bae824f62aeb0598d263c30f7",
      "f3d49e17947c408a86657086b9a7a0cc",
      "889ae377e6ec4968a3e5322590bf9b24",
      "9f09831cf9d247298704d7d33e44a605",
      "12617104808c4e66b2fca713090e53cd",
      "cf91b2aa8221470986d0669ce499048f",
      "da8afc6f0f234ad2b52745fd6f8466a5",
      "28efd56d77a24f0a9fd6557c4355c948",
      "93fc678152574519997efeec08823720",
      "a36dbc3819c247c7a05f809ad4ce5a66"
     ]
    },
    "id": "Cn29KlG-6nNU",
    "outputId": "282b1103-f368-4d62-eae0-f5942c9aeebd"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6690e407e6e645f28e83bbb122750420"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 50 | Num Epochs = 4 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 4,505,600/4,000,000,000 (0.11% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.449500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.296500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.268100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.263900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.34545231580734254, metrics={'train_runtime': 44.9932, 'train_samples_per_second': 4.445, 'train_steps_per_second': 2.223, 'total_flos': 73138553929728.0, 'train_loss': 0.34545231580734254})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3D: Save initial checkpoint\n",
    "\n",
    "model.save_pretrained(\"sft-initial-checkpoint\")\n",
    "tokenizer.save_pretrained(\"sft-initial-checkpoint\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4eH-YCL6nQQ",
    "outputId": "8d11e60d-7870-421f-ee2d-24dd08113215"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('sft-initial-checkpoint/tokenizer_config.json',\n",
       " 'sft-initial-checkpoint/special_tokens_map.json',\n",
       " 'sft-initial-checkpoint/tokenizer.model',\n",
       " 'sft-initial-checkpoint/added_tokens.json',\n",
       " 'sft-initial-checkpoint/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4A: Load custom checkpoint\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"sft-initial-checkpoint\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    "    device_map={\"\": 0},\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEoZzlot6nTC",
    "outputId": "387db7e1-0dae-46f1-ab27-a091bc64c388"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4B: Domain support fine-tuning data\n",
    "\n",
    "domain_data = [\n",
    "    {\"text\": \"User: How do I view my billing history?\\nAssistant: You can view your billing history under the account settings.\"},\n",
    "    {\"text\": \"User: Is there an option to pause my subscription?\\nAssistant: Yes, you can pause your subscription from your account dashboard.\"},\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(domain_data)\n",
    "dataset = dataset.map(format_prompt)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "88df4663de91452ab4af408bd261b6d2",
      "da371e6038dd4b3e960918e4d33f3638",
      "060d0f073c904370bd15d8a05d36c836",
      "ff5d36a411bf4a2085cfa42c0af890e2",
      "c748a217a83b4d1cb74f900aae00c1a5",
      "20440a6142fc4ec2b8b9c4cf477579f7",
      "76f6ca26f03943c29b2540d3b87bca83",
      "759e38163d654ca49288d914bd9e5cd9",
      "5ed7476807574e6d92f90eb07f1e92a4",
      "488239ad46324ed6a2350c89e3431079",
      "c42cd48e513a4023ae23afd1f4877044"
     ]
    },
    "id": "_s2wO9u06rSz",
    "outputId": "d2626d81-bf99-4479-b40d-8f22541cff9f"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88df4663de91452ab4af408bd261b6d2"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4C: Continue fine-tuning\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sft-continued-checkpoint1\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=100,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save checkpoint\n",
    "model.save_pretrained(\"sft-continued-checkpoint1\")\n",
    "tokenizer.save_pretrained(\"sft-continued-checkpoint1\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908,
     "referenced_widgets": [
      "7d1333d5c5a04ba0a6266700b94bbaf4",
      "2a07451da89d45089782787092acf67a",
      "d603f69b3cf142cfaa199e9d3148a1ce",
      "e8872f5ea3ff464f82f5136eb0c09fb1",
      "03d4570716644b1c8f59709f56072951",
      "fe9b7bbe102c4ffc947e16aaf5e5f86c",
      "bdbac252bd5648aeae18d949daac2023",
      "d736e9f1c14e46a7889d52ca9c9126c0",
      "f610cad5433343cea2e8136f3e4f4ed6",
      "5f7859438a7e458597b91512f94e2740",
      "d33682010964471ead5297401878b82a"
     ]
    },
    "id": "zB6LJs5j6rVX",
    "outputId": "ebad16e7-06ee-4db7-ac08-b918f7898b94"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d1333d5c5a04ba0a6266700b94bbaf4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2 | Num Epochs = 100 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 4,505,600/4,000,000,000 (0.11% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:35, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('sft-continued-checkpoint1/tokenizer_config.json',\n",
       " 'sft-continued-checkpoint1/special_tokens_map.json',\n",
       " 'sft-continued-checkpoint1/tokenizer.model',\n",
       " 'sft-continued-checkpoint1/added_tokens.json',\n",
       " 'sft-continued-checkpoint1/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "qG-8jMgu8fLD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "AqsxnDs18f_I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fse8j-FY8gCD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5A: Load previous checkpoint\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"sft-continued-checkpoint1\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    "    device_map={\"\": 0},\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPHkq13B6uV3",
    "outputId": "6bd8a5eb-7ef0-407a-c9f7-6a6970ac29d3"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5B: Customer service dialogues\n",
    "\n",
    "customer_service = [\n",
    "    {\"text\": \"User: How can I delete my account?\\nAssistant: You can delete your account by contacting customer support.\"},\n",
    "    {\"text\": \"User: Can I get a refund for a canceled order?\\nAssistant: Refunds are processed automatically for eligible cancellations.\"},\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(customer_service)\n",
    "dataset = dataset.map(format_prompt)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d1a4d4fffeb544d099e5eed1930c3b22",
      "7133124c78004f218bbcd3ebf6bf83a7",
      "0fef9c7c11d24ead98046baf16f99ac3",
      "34200c5b414f44198ce4acc5f99cc786",
      "27a828a52e314a47802bddd98b4f42d4",
      "fd97255d467e4bea821f3f118633712d",
      "e5b06ee1b3464e82a5e05e5acc79e465",
      "b29fc1675d5a4c3baeb5e43e627297cc",
      "7c8157ec6beb445a8f84770980d8250d",
      "1f9429a344d24efcb66ab011ad8d90a3",
      "f114fd668d914ebba6efe3e5375c86b0"
     ]
    },
    "id": "Und1Xmrs6uY8",
    "outputId": "9212b6ee-30b4-4f8c-e1fd-68aea18dffa2"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1a4d4fffeb544d099e5eed1930c3b22"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5C: Continue fine-tuning again\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sft-continued-checkpoint2\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=100,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save final checkpoint\n",
    "model.save_pretrained(\"sft-continued-checkpoint2\")\n",
    "tokenizer.save_pretrained(\"sft-continued-checkpoint2\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908,
     "referenced_widgets": [
      "5db96ac2972541478ebb3dd95ffaf4f8",
      "5cba9e774cb14b9d9575e080dc0f2cdc",
      "c199c8ed96ef4cfebb3d5f70afa5e420",
      "4eac84d255bb46f4ae1ad78329b21c2d",
      "0623e7ff77da4b748661d659f8234922",
      "f6ec717cdccb4d32bd7cd5336b4378af",
      "717848256cc24a32a45d3f02b53b7592",
      "f49efd892a844318b02bf5aeff24b272",
      "b6694af3fb1146689714ca0e47b2923d",
      "169f2d3ceb6a45178dfdcaf4e66f1af4",
      "693219609f0b4056b2c2b7bf5c578f97"
     ]
    },
    "id": "qX6aMuKU6w3d",
    "outputId": "a27c2206-7310-4e03-8c44-2de43930198b"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5db96ac2972541478ebb3dd95ffaf4f8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2 | Num Epochs = 100 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 4,505,600/4,000,000,000 (0.11% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:28, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('sft-continued-checkpoint2/tokenizer_config.json',\n",
       " 'sft-continued-checkpoint2/special_tokens_map.json',\n",
       " 'sft-continued-checkpoint2/tokenizer.model',\n",
       " 'sft-continued-checkpoint2/added_tokens.json',\n",
       " 'sft-continued-checkpoint2/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 6: Final testing after multiple fine-tunings\n",
    "\n",
    "def generate_response_final(prompt, max_tokens=128):\n",
    "    chat_prompt = f\"<|im_start|>user\\n{prompt}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()\n",
    "\n",
    "# Inference\n",
    "print(\"\\nTest 1:\")\n",
    "print(generate_response_final(\"Can I pause my subscription temporarily?\"))\n",
    "\n",
    "print(\"\\nTest 2:\")\n",
    "print(generate_response_final(\"How can I get a refund for a canceled order?\"))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0qQJSNn6w6m",
    "outputId": "bfac8d93-4ddb-42e3-c795-57570b47d9b9"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test 1:\n",
      "There is no cancellation fee for paused subscriptions.\n",
      "<|im\n",
      "\n",
      "Test 2:\n",
      "There is a $20 cancellation fee for an invalid order.\n"
     ]
    }
   ]
  }
 ]
}