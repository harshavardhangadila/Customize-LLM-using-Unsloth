# Customize-LLM-using-Unsloth

| **Task** | **Key Activities & Sub-Tasks** | **Datasets / Sources** | **Model(s) & Settings** | **Outputs / Artifacts** |
|:--------:|:-------------------------------|:-----------------------|:------------------------|:------------------------|
| **A – Core Fine-Tuning**<br/>(TinyLlama 1.1B) | - A1 Instruction Chat: Q&A / Instruction following.<br/>- A2 Classification Chat: IMDB Sentiment.<br/>- A3 Conversation Chat: Multi-turn Samsum Dialogues.<br/>- A4 Extended Context: Extended to 4096 tokens. | Alpaca (52k subset)<br/>IMDB Sentiment (1k)<br/>Samsum Dialogue (2k) | TinyLlama/TinyLlama-1.1B-Chat-v1.0<br/>LoRA (r=16, α=16)<br/>4096 context | - 4 Fine-tuned checkpoints.<br/>- Demonstrated Q&A, sentiment, multi-turn chat, 4K tokens. |
| **B – Continued Pre-training** | - Simulated fictional language.<br/>- Continued causal pre-training with Unsloth. | 20-sentence synthetic corpus (fictional language) | TinyLlama LoRA<br/>Causal Language Modeling<br/>5 epochs | - New checkpoint able to generate sentences in fictional language style. |
| **C – Multi-Dataset Chat Templates** | - Combined classification + chat tasks.<br/>- Used ChatML / OpenChat templates.<br/>- Merged 2k examples (IMDB + Samsum). | IMDB Sentiment<br/>Samsum Dialogue | TinyLlama LoRA<br/>4096 tokens context<br/>100 steps SFTTrainer | - Multi-task model handling classification and chat tasks together. |
| **D – Reward Modeling** | - ORPO Fine-tuning (Intel/orca_dpo_pairs, 10k).<br/>- DPO Fine-tuning (same dataset, 5k subset). | Intel/orca_dpo_pairs | TinyLlama LoRA<br/>ORPOTrainer<br/>DPOTrainer<br/>300 steps | - Two checkpoints: ORPO and DPO.<br/>- Model aligned to prefer better responses. |
| **E – Continued Fine-Tuning Chain** | - Stage 1: General Knowledge Chatbot.<br/>- Stage 2: Billing Support Fine-tuning.<br/>- Stage 3: Customer Service Support. | Synthetic Q&A sets<br/>(20 samples per domain) | TinyLlama LoRA<br/>100 steps per stage<br/>Chained checkpoints | - Three sequential checkpoints showing increasing specialization in domain understanding. |
| **F – Mental Health Chatbot** | - Created 500 mental health instruction-response samples.<br/>- Fine-tuned TinyLlama for mental wellness dialogue.<br/>- Tested on new unseen mental health queries. | 500 synthetic mental health Q&A pairs | TinyLlama LoRA<br/>100 steps fine-tuning | - Fine-tuned Mental Health Chatbot.<br/>- Model responding empathetically to stress, anxiety, loneliness prompts. |
| **G – Export to Ollama** | - Merged LoRA adapters.<br/>- Saved Huggingface full model.<br/>- Exported to GGUF (q4_k_m).<br/>- Created Modelfile.<br/>- Verified inference. | TinyLlama checkpoint from Task F | TinyLlama full model (merged)<br/>GGUF export<br/>Quantized q4_k_m | - `tinyllama_mentalhealth_gguf/` folder:<br/>• model.gguf<br/>• tokenizer.json<br/>• Modelfile<br/>- Ready for Ollama import and local running. |


Youtube: [Customize-LLM-using-Unsloth](https://www.youtube.com/playlist?list=PLCGwaUpxPWO2KKyJX_Ic9eQu7ZRu1b1JG)
